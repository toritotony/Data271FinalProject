{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA271 Final Project - California Call for Service Analysis\n",
    "\n",
    "---\n",
    "\n",
    "## Research Details\n",
    "\n",
    "---\n",
    "\n",
    "### Introducing the Problem\n",
    "I'll be performing a statistical investigative process to explore and analyze police call-for-service data in conjunction with meteorologic and demographic datasets to identify trends that can inform alternative policing models and highlight potential overallocations of resources in certain district areas. Paired with general census-collected information, weather reports, and similar contextual data, this project will aim to identify patterns and use them to determine common stressors and causes behind the influx of emergency service requests.\n",
    "\n",
    "---\n",
    "\n",
    "### Addressing the Problem\n",
    "My approach will involve joining datasets on their dates to analyze time series across years, looking for patterns and distributions of calls and weather readings, and finding correlations between attributes that can help us anticipate problems using data-driven insights. This aims to avoid overwhelming the public with a presence that can be counterproductive—especially in the era of police brutality and avoidable encounters involving individuals reporting non-violent crimes who may not receive proper care or treatment.\n",
    "\n",
    "The analysis should support municipal governments and police agencies by helping reduce resource and labor costs through more effective resource allocation. The goal is to provide actionable statistics that motivate agencies to reconsider how officers are distributed and how certain calls are addressed. We can also support this by identifying correlations between call types and environmental or demographic factors to help build profiles of neighborhoods or districts that vary across cities, counties, and states. Below are some articles that elaborate further and show how others have tackled similar problems:\n",
    "\n",
    "- [Medium article about alternative policing models for non-violent calls](https://londonbreed.medium.com/alternatives-to-police-for-responding-to-non-violent-911-calls-44c7d40ad9b1)\n",
    "- [CNA article on alternative 911 dispatch models](https://www.cna.org/quick-looks/2022/alternative-911-dispatch-models)\n",
    "- [Police Chief Magazine article about data-driven policing methods](https://www.policechiefmagazine.org/turning-point-policing-methods/)\n",
    "\n",
    "---\n",
    "\n",
    "### Analysis Breakdown\n",
    "We ask the following questions before conducting our official exploratory data analysis:\n",
    "\n",
    "- How can we use a data-driven strategy to reduce the physical presence of officers, lower labor and resource costs, and shorten dispatch times when dealing with nonviolent calls?\n",
    "- How can we combine insights from these calls—including their characteristics and any reported alleged crimes—with general census and weather data to better allocate resources and determine the necessary equipment for specific districts or situations, thereby minimizing unnecessary costs and overly aggressive responses?\n",
    "- Can we identify a clear correlation between the environmental factors of cities and counties and the nature or frequency of calls for service, enabling us to predict these calls with reasonable accuracy?\n",
    "\n",
    "Our analysis will be broken down into the following stages, with specific techniques designed to help tell a meaningful and data-driven story:\n",
    "\n",
    "1. **Explore Individual Datasets**  \n",
    "   Perform exhaustive exploratory data analysis (EDA) on each dataset individually—transforming variables, cleaning data, checking for missing values and outliers, and applying descriptive statistics to uncover underlying patterns. This includes identifying correlations between variables, exploring distribution shapes (e.g., bimodality), and applying statistical tests such as ANOVA, chi-squared tests, and bootstrapping where appropriate.\n",
    "\n",
    "2. **Analyze Combined Datasets**  \n",
    "   Join datasets on date fields and other shared keys to analyze time-based and cross-variable relationships. Use visual encodings (e.g., color hues) to compare grouped variables—such as call types across weather conditions or demographic segments. Generate geographic heat maps to visualize spatial distributions of call frequency across U.S. districts or counties, and begin to connect attributes across contexts (e.g., weather with crime type, or demographics with call volume).\n",
    "\n",
    "3. **Evaluate Significance and Observational Limitations**  \n",
    "   Assess whether observed trends and correlations meaningfully address our original research questions. This includes evaluating both statistical and practical significance, while recognizing that results are drawn from observational data and cannot confirm causation. Even if certain relationships appear weak or inconclusive, this stage helps clarify the limits of current data and guides interpretation responsibly.\n",
    "\n",
    "4. **Answer Research Questions**  \n",
    "   Revisit the original questions in light of the findings. Identify which questions can be confidently addressed with the available data and which remain unresolved due to data limitations or ambiguous patterns. This stage will help form the basis for final insights and conclusions.\n",
    "\n",
    "5. **Recommendations & Further Exploration**\n",
    "   Based on findings, propose actionable recommendations for improving resource allocation or dispatch policies. Highlight areas where deeper or more granular data could yield stronger insights and suggest directions for future research or experimentation.\n",
    "\n",
    "---\n",
    "\n",
    "### Datasets\n",
    "1. [PD's Call for Service Data](https://humboldtgov.org/2161/Daily-CFS-Report)  \n",
    "2. [CALMAC Weather Files](https://www.calmac.org/weather.asp)  \n",
    "3. [Census Bureau Data](https://data.census.gov)  \n",
    "4. [State of CA DOJ Crime Data](https://oag.ca.gov/crime)\n",
    "\n",
    "---\n",
    "\n",
    "### Libraries & Modules\n",
    "- **Pandas:** Efficiently works with tabular data retrieved via API or download  \n",
    "- **Numpy:** Performs element-wise arithmetic and advanced mathematical operations  \n",
    "- **Matplotlib:** Core visualization library, used to produce basic plots and supports Seaborn  \n",
    "- **Seaborn:** Built on Matplotlib, provides additional high-level statistical plots  \n",
    "- **Sodapy:** Accesses Socrata Open Data API, useful for open government datasets  \n",
    "- **Plotnine:** Uses a grammar-of-graphics approach for elegant and expressive data visualizations  \n",
    "\n",
    "---\n",
    "\n",
    "### Project Resources\n",
    "- [GitHub Repository](https://github.com/toritotony/Data271FinalProject)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting Data\n",
    "Here we collect the data sets mentioned above, across 2015-2025 so we can avoid outlier information that might come from COVID outbreak in 2020. \n",
    "\n",
    "I'll precede each retrieval with the corresponding dataset, the source of retrieval, and further details regarding it's purpose and when it was collected.\n",
    "\n",
    "After collection we'll list the variables available to us, what tehy mean, and any immediate findings that we can identify after looking at its description and information in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sodapy import Socrata\n",
    "import random\n",
    "import numpy as np\n",
    "from plotnine import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Statistics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Above to Answer Questions using Inferential Statistics and Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer Questions and Conclude Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References and Citations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
